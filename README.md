# Epistemology of Language Models: Do Language Models Have Holistic Knowledge?

[Paper](https://arxiv.org/pdf/2403.12862)

This paper investigates the inherent knowledge in language models from the perspective of epistemological holism. The purpose of this paper is to explore whether LLMs exhibit characteristics consistent with epistemological holism. These characteristics suggest that core knowledge, such as general scientific knowledge, each plays a specific role, serving as the foundation of our knowledge system and being difficult to revise. To assess these traits related to holism, we created a scientific reasoning dataset and examined the epistemology of language models through three tasks: Abduction, Revision, and Argument Generation. In the abduction task, the language models explained situations while avoiding revising the core knowledge. However, in other tasks, the language models were revealed not to distinguish between core and peripheral knowledge, showing an incomplete alignment with holistic knowledge principles.

This dataset is designed to test whether language models possess a network structure of holistic knowledge. Specifically, it examines how language models respond when they encounter sentences that contradict general knowledge, commonsense (counterexamples): whether they deny commonsense or reject the counterexample.

## Data Content and Format
